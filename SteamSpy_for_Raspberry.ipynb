{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  This is an API for Steam Spy. It accepts requests in GET string and returns data in JSON arrays.\n",
    "\n",
    "  Allowed poll rate - 4 requests per second.\n",
    "\n",
    "  ## Examples: ##\n",
    "   \n",
    "  * http://steamspy.com/api.php?request=appdetails&appid=730 - returns data for Counter-Strike: Global Offensive\n",
    "  * http://steamspy.com/api.php?request=top100in2weeks - return Top 100 apps by players in the last two weeks\n",
    "\t\t\n",
    "\n",
    "  ## Common parameters: ##\n",
    " \n",
    "  * request - code for API request call.\n",
    "  * appid - Application ID (a number).\n",
    "\n",
    "\n",
    "  ## Accepted requests: ##\n",
    "  \n",
    "  ### appdetails ###\n",
    "\n",
    "  Returns details for the specific application. Requires *appid* parameter.  \n",
    "\n",
    "  ### genre ###\n",
    "\n",
    "  Returns games in this particular genre. Requires *genre* parameter and works like this:\n",
    "  \n",
    "  * http://steamspy.com/api.php?request=genre&genre=Early+Access\n",
    "\n",
    "\n",
    "  ### top100in2weeks ###\n",
    "\n",
    "  Returns Top 100 games by players in the last two weeks.\n",
    "\n",
    "  ### top100forever ###\n",
    "\n",
    "  Returns Top 100 games by players since March 2009.\n",
    "\n",
    "  ### top100owned ###\n",
    "\n",
    "  Returns Top 100 games by owners.\n",
    "\n",
    "  ### all ###\n",
    "\n",
    "  Returns all games with owners data sorted by owners.\n",
    "\n",
    "\n",
    "  ## Return format for an app: ##\n",
    "\n",
    "  * appid - Steam Application ID. If it's 999999, then data for this application is hidden on developer's request, sorry.\n",
    "  * name - the game's name\n",
    "  * developer - comma separated list of the developers of the game\n",
    "  * publisher - comma separated list of the publishers of the game\n",
    "  * score_rank - score rank of the game based on user reviews\n",
    "  * owners - owners of this application on Steam. **Beware of free weekends!**\n",
    "  * owners_variance - variance in owners. The real number of owners lies somewhere on owners +/- owners_variance range.   \n",
    "  * players_forever - people that have played this game since March 2009.\n",
    "  * players_forever_variance - variance for total players.\n",
    "  * players_2weeks - people that have played this game in the last 2 weeks.\n",
    "  * players_2weeks_variance - variance for the number of players in the last two weeks. \n",
    "  * average_forever - average playtime since March 2009. In minutes.\n",
    "  * average_2weeks - average playtime in the last two weeks. In minutes.\n",
    "  * median_forever - median playtime since March 2009. In minutes.\n",
    "  * median_2weeks - median playtime in the last two weeks. In minutes.\n",
    "  * ccu - peak CCU yesterday.\n",
    "  * price - US price in cents.\n",
    "  * tags - the game's tags with votes in JSON array\n",
    "\n",
    "\n",
    "  ## Questions? ##\n",
    "\n",
    "  Contact me by e-mail: *sergey at galyonkin dot com*.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime\n",
    "import telegram\n",
    "import pyprind\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download all data of the current day and store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def downloadAPI():\n",
    "    # Download the data and parse it\n",
    "    url = 'http://steamspy.com/api.php?request=all'\n",
    "    data = requests.get(url)#.json()\n",
    "    print(data)\n",
    "\n",
    "    # Store the data in file named by the date\n",
    "    with open('API/{}_SteamSpy_API.json'.format(datetime.date.today()), 'w') as file:\n",
    "        json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the deals and store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def downloadDeals():\n",
    "    # Get the html-code and parse it\n",
    "    url = 'http://steamspy.com/deal/'\n",
    "    html = requests.get(url).text\n",
    "    bs = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    deals = []\n",
    "    # Iterate over each game in the list\n",
    "    for game in bs.find('tbody').findAll('tr'):\n",
    "        data = [td.get_text().strip() for td in game.findAll('td')]\n",
    "\n",
    "        # Extract, format and parse the data\n",
    "        try:\n",
    "            rank = int(data[0])\n",
    "        except:\n",
    "            rank = None\n",
    "        try:\n",
    "            name = data[1]\n",
    "        except:\n",
    "            name = None\n",
    "        try:\n",
    "            appid = int(game.find('a')['href'].rsplit('/', 1)[-1])\n",
    "        except:\n",
    "            appid = None\n",
    "        try:\n",
    "            release = data[2]\n",
    "        except:\n",
    "            release = None\n",
    "        try:\n",
    "            old_price = float(data[3].rsplit('$', 1)[-1][:-1])\n",
    "        except:\n",
    "            old_price = None\n",
    "        try:\n",
    "            discount = float(data[4][:-1])\n",
    "        except:\n",
    "            discount = None\n",
    "        try:\n",
    "            score_rank = float(data[5].split('%', 1)[0])\n",
    "        except:\n",
    "            score_rank = None\n",
    "        try:\n",
    "            owners = int(data[6].split(' ')[0].replace(',', ''))\n",
    "        except:\n",
    "            owners = None\n",
    "        try:\n",
    "            owners_var = int(data[6].split(' ')[1][1:].replace(',', ''))\n",
    "        except:\n",
    "            owners_var = None\n",
    "        try:\n",
    "            players = int(data[7].split(' ')[0].replace(',', ''))\n",
    "        except:\n",
    "            players = None\n",
    "        try:\n",
    "            players_var = int(data[7].split(' ')[1][1:].replace(',', ''))\n",
    "        except:\n",
    "            players_var = None\n",
    "        try:\n",
    "            hours, minutes = data[8].split(' ')[0].split(':')\n",
    "            play_time_mean = int(hours)*60+int(minutes)\n",
    "        except:\n",
    "            play_time_mean = None\n",
    "        try:\n",
    "            hours, minutes = data[8].split(' ')[1][1:-1].split(':')\n",
    "            play_time_median = int(hours)*60+int(minutes)\n",
    "        except:\n",
    "            play_time_median = None\n",
    "\n",
    "        # Collect the data\n",
    "        deals.append([rank, name, appid, release, old_price, discount, score_rank, owners, owners_var, players, players_var, play_time_mean, play_time_median])\n",
    "\n",
    "    # Parse the data and store it in a file\n",
    "    df = pd.DataFrame(deals, columns=['Rank', 'Name', 'App_ID', 'Release', 'Old_Price', 'Discount', 'Score_Rank', 'Owners', 'Owners_Variance', 'Players', 'Players_Variance', 'Play_Time_Mean', 'Play_Time_Median'])\n",
    "    df['Release'] = pd.to_datetime(df['Release'])\n",
    "    df.to_csv('Deals/{}_Deals.csv'.format(datetime.date.today()), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the Countries' Ranks and store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def downloadCountryRanks():\n",
    "    # Get the html-code and parse it\n",
    "    url = 'https://steamspy.com/country/'\n",
    "    html = requests.get(url).text\n",
    "    bs = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    # Pattern to extract the names\n",
    "    pattern = re.compile('[1-5]\\. ')\n",
    "\n",
    "    countries = []\n",
    "    # Iterate over each country\n",
    "    for row in bs.find('tbody').findAll('tr'):\n",
    "        entries = row.findAll('td')\n",
    "\n",
    "        # Extract the data\n",
    "        country = entries[1].get_text()\n",
    "        country_link = entries[1].find('a')['href'].rsplit('/', 1)[-1]\n",
    "        games_per_user = float(entries[2].get_text())\n",
    "        time = entries[3].get_text().split(':')\n",
    "        time = 60*int(time[0]) + int(time[1])\n",
    "        owned_games = re.split(pattern, entries[4].get_text())[1:]\n",
    "        owned_games = list(zip(list(range(1,6)), owned_games, ['Most Owned Games']*5))\n",
    "        favorite_games = re.split(pattern, entries[5].get_text())[1:]\n",
    "        favorite_games = list(zip(list(range(1,6)), favorite_games, ['Favorite Games (2 Weeks)']*5))\n",
    "\n",
    "        # Iterate over the ranks\n",
    "        for rank in owned_games+favorite_games:\n",
    "            countries.append([country, country_link, games_per_user, time, rank[0], rank[1], rank[2]])\n",
    "\n",
    "    # Parse and save the data\n",
    "    df = pd.DataFrame(countries, columns=['Country', 'Country_Link', 'Games_Per_User', 'Minutes (2 Weeks)', 'Rank', 'Name', 'Category'])\n",
    "    df.to_csv('Country_Ranks/{}_Countries.csv'.format(datetime.date.today()), index=False)\n",
    "    return df['Country_Link'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the Countries' Games and store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def downloadCountries():\n",
    "    country_games = []\n",
    "    country_data = []\n",
    "\n",
    "    # Patterns for the data\n",
    "    pat_country = re.compile('\\n\\n(.*?)Total')\n",
    "    pat_active_users = re.compile('Total active users: (.*?) ±')\n",
    "    pat_active_users_variance = re.compile(' ± (.*?)Share of total users:')\n",
    "    pat_share_total_users = re.compile('Share of total users: (.*?)%Share of total games:')\n",
    "    pat_share_total_games = re.compile('Share of total games: (.*?)%Owned games per user:')\n",
    "    pat_games_per_user = re.compile('Owned games per user: (.*?)Average playtime \\(2 weeks\\):')\n",
    "    pat_average_playtime_2_weeks = re.compile('Average playtime \\(2 weeks\\): (.*?)Average playtime \\(total\\):')\n",
    "    pat_average_playtime_total = re.compile('Average playtime \\(total\\): (.*?)Active users \\(2 weeks\\):')\n",
    "    pat_active_users_2_weeks = re.compile('Active users \\(2 weeks\\): (.*?)%Active users \\(total\\):')\n",
    "    pat_active_users_total = re.compile('Active users \\(total\\): (.*?)%')\n",
    "\n",
    "    # Iterate over every country\n",
    "    bar = pyprind.ProgPercent(len(country_links))\n",
    "    for link in country_links:\n",
    "        # Get the html-code and parse it\n",
    "        url = 'http://steamspy.com/country/{}'.format(link)\n",
    "        html = requests.get(url).text\n",
    "        bs = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "        # Get the Country-Data\n",
    "        text = bs.find('div', {'class':'panel panel-transparent'}).get_text().strip()\n",
    "        country = re.search(pat_country, text).group(1)\n",
    "        active_users = int(re.search(pat_active_users, text).group(1).replace(',', ''))\n",
    "        active_users_variance = int(re.search(pat_active_users_variance, text).group(1).replace(',', ''))\n",
    "        share_total_users = float(re.search(pat_share_total_users, text).group(1))\n",
    "        share_total_games = float(re.search(pat_share_total_games, text).group(1))\n",
    "        games_per_user = float(re.search(pat_games_per_user, text).group(1))\n",
    "        hours, minutes = re.search(pat_average_playtime_2_weeks, text).group(1).split(':')\n",
    "        average_playtime_2_weeks = 60*int(hours)+int(minutes)\n",
    "        hours, minutes = re.search(pat_average_playtime_total, text).group(1).split(':')\n",
    "        average_playtime_total = 60*int(hours)+int(minutes)\n",
    "        active_users_2_weeks = float(re.search(pat_active_users_2_weeks, text).group(1))\n",
    "        active_users_total = float(re.search(pat_active_users_total, text).group(1))\n",
    "\n",
    "        # Store the Country-Data\n",
    "        country_data.append([country, active_users, active_users_variance, share_total_users, share_total_games, games_per_user, average_playtime_2_weeks, average_playtime_total, active_users_2_weeks, active_users_total])\n",
    "\n",
    "        # Iterate over every game\n",
    "        for game in bs.find('tbody').findAll('tr'):\n",
    "            data = [td.get_text().strip() for td in game.findAll('td')]\n",
    "\n",
    "            # Gather the data\n",
    "            try:\n",
    "                rank = int(data[0])\n",
    "            except:\n",
    "                rank = None\n",
    "            try:\n",
    "                name = data[1]\n",
    "            except:\n",
    "                name = None\n",
    "            try:\n",
    "                appid = int(game.find('a')['href'].rsplit('/', 1)[-1])\n",
    "            except:\n",
    "                appid = None\n",
    "            try:\n",
    "                player_percentage_2_weeks = float(data[2][:-1])/100\n",
    "            except:\n",
    "                player_percentage_2_weeks = None\n",
    "            try:\n",
    "                hours, minutes = data[3].split(':')\n",
    "                average_hours_2_weeks = int(hours)*60+int(minutes)\n",
    "            except:\n",
    "                average_hours_2_weeks = None\n",
    "            try:\n",
    "                players_percentage_total = float(data[4][:-1])/100\n",
    "            except:\n",
    "                players_percentage_total = None\n",
    "            try:\n",
    "                hours, minutes = data[5].split(':')\n",
    "                average_hours_total = int(hours)*60+int(minutes)\n",
    "            except:\n",
    "                average_hours_total = None\n",
    "            try:\n",
    "                library_share = float(data[6][:-1])/10000\n",
    "            except:\n",
    "                library_share = None\n",
    "\n",
    "            # Store the data\n",
    "            country_games.append([country, rank, name, appid, player_percentage_2_weeks, average_hours_2_weeks, players_percentage_total, average_hours_total, library_share])\n",
    "        \n",
    "        time.sleep(1)\n",
    "        bar.update()\n",
    "\n",
    "    # Save country_games to file\n",
    "    df = pd.DataFrame(country_games, columns=['Country', 'Rank', 'Name', 'App_ID', 'Player_Percentage_2_Weeks', 'Average_Hours_2_Weeks', 'Players_Percentage_Total', 'Average_Hours_Total', 'Library_Share'])\n",
    "    df.to_csv('Country_Games/{}_Games_Country.csv'.format(datetime.date.today()), index=False)\n",
    "\n",
    "    # Save country_data to file\n",
    "    df = pd.DataFrame(country_data, columns=['Country', 'Active_Users', 'Active_Users_Variance', 'Share_Total_Users', 'Share_Total_Games', 'Games_Per_User', 'Average_Playtime_2_Weeks', 'Average_Playtime_Total', 'Active_Users_2_Weeks', 'Active_Users_Total'])\n",
    "    df.to_csv('Country_Data/{}_Country_Data.csv'.format(datetime.date.today()), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def botMessage(message):\n",
    "    bot = telegram.Bot(token='')\n",
    "    bot.send_message(chat_id=0, text=message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def folderStructure():\n",
    "    for folder in ['API', 'Deals', 'Country_Ranks', 'Country_Games', 'Country_Data']:\n",
    "        if folder not in os.listdir():\n",
    "            os.mkdir(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the Programm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[100 %] Time elapsed: 00:02:16 | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:16\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    folderStructure()\n",
    "    \n",
    "    try:\n",
    "        downloadAPI()\n",
    "    except:\n",
    "        print('1')\n",
    "    try:\n",
    "        downloadDeals()\n",
    "    except:\n",
    "        print('2')\n",
    "    try:\n",
    "        country_links = downloadCountryRanks()\n",
    "    except:\n",
    "        print('3')\n",
    "    try:\n",
    "        downloadCountries()\n",
    "    except:\n",
    "        print('4')\n",
    "    \n",
    "    message = 'Gamestar: Alles gut gelaufen'\n",
    "    botMessage(message)\n",
    "except:\n",
    "    message = 'Gamestar: Fehler aufgetreten!'\n",
    "    botMessage(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
